<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Understanding nix fork concurrency</title>
        <link href="css/style.css" rel="stylesheet" type="text/css"/>
        <meta charset="utf-8"/>
<meta content="urn:uuid:dd0ab1fe-cf2d-4e17-8acb-531b7ebebf1a" name="Adept.expected.resource"/>
    </head>

    <body>
        <section>

                            <header>
                    <h1 class="header-title">Understanding nix fork concurrency</h1>
                </header>
            
            <article>
                
<p>Before threads were introduced as a standard for POSIX operating systems in 1995, the best option available for concurrency was <kbd>fork</kbd>. On these operating systems, <kbd>fork</kbd> was a fairly primitive command that allowed programs to create copies of themselves as child processes. The name <kbd>fork</kbd> comes from the idea of taking one process and splitting it into two.</p>
<p><kbd>fork</kbd> is not platform-independent, specifically it is not available on Windows, and we recommend using threads instead. However, for educational purposes, it is helpful to introduce some of the concepts from <kbd>fork</kbd> because they are also relevant to threaded programming.</p>
<p>The following code is a translation of the precedingÂ <kbd>process_a</kbd>, <kbd>process_b</kbd> example to use <kbd>fork</kbd>:</p>
<pre class="p1"><span class="s1">extern crate nix;<br/></span><span class="s1">use nix::unistd::{fork,ForkResult};<br/></span><span class="s1">use std::{thread,time};<br/></span><span class="s1">use std::process;<br/><br/></span><span class="s1">fn main() {<br/></span><span class="s1">   let mut children = Vec::new();<br/></span><span class="s1">   for _ in 0..3 {<br/></span><span class="s1">      match fork().expect("fork failed") {<br/></span><span class="s1">         ForkResult::Parent{ child: pid } =&gt; { children.push(pid); }<br/></span><span class="s1">         ForkResult::Child =&gt; {<br/></span><span class="s1">            let t = time::Duration::from_millis(1000);<br/></span><span class="s1">            loop {<br/></span><span class="s1">               println!("child process #{}", process::id());<br/></span><span class="s1">               thread::sleep(t);<br/></span><span class="s1">            }<br/></span><span class="s1">         }<br/></span><span class="s1">      }<br/></span><span class="s1">   }<br/></span><span class="s1">   let t = time::Duration::from_millis(1000);<br/></span><span class="s1">   loop {<br/></span><span class="s1">      println!("parent process #{}", process::id());<br/></span><span class="s1">      thread::sleep(t);<br/></span><span class="s1">   }<br/></span><span class="s1">}</span></pre>
<p>In this example, the parent-child relationship is very similar to our first example. We have three children running and one parent managing them.</p>
<p>It should be noted that forked processes share memory initially. Only when either process modifies its memory, will the operating system then perform an operation called <strong>copy-on-write</strong>, duplicating the memory. This behavior is a first step into shared memory between running processes.</p>
<p>To demonstrate copy-on-write, let's allocate 200 MB of memory and fork 500 processes. Without copy-on-write, this would be 100 GB and would crash most personal computers. Consider the following code:</p>
<pre class="p1" style="padding-left: 30px"><span class="s1">extern crate nix;<br/></span><span class="s1">use nix::unistd::{fork};<br/></span><span class="s1">use std::{thread,time};<br/><br/></span><span class="s1">fn main() {<br/></span><span class="s1">   let mut big_data: Vec&lt;u8&gt; = Vec::with_capacity(200000000);<br/></span><span class="s1">   big_data.push(1);<br/></span><span class="s1">   big_data.push(2);<br/></span><span class="s1">   big_data.push(3);<br/></span><span class="s1">   //Both sides of the fork, will continue to fork<br/></span><span class="s1">   //This is called a fork bomb<br/></span><span class="s1">   for _ in 0..9 {<br/></span><span class="s1">      fork().expect("fork failed");<br/></span><span class="s1">   }<br/></span><span class="s1">   //2^9 = 512<br/><br/></span><span class="s1">   let t = time::Duration::from_millis(1000);<br/></span><span class="s1">   loop {<br/>      //copy on write, not on read<br/></span><span class="s1">      big_data[2];<br/></span><span class="s1">      thread::sleep(t);<br/></span><span class="s1">   }<br/></span><span class="s1">}</span></pre>
<p>Many resources from the parent process also remain available and safe to use from the child process. This is very useful for server applications that listen on a socket in the parent process and poll for incoming connections in the child process. This simple trick permits server applications to distribute work across worker processes:</p>
<pre class="p1" style="padding-left: 30px">extern crate nix;<span class="s1"><br/></span><span class="s1">use nix::unistd::{fork,ForkResult};<br/></span><span class="s1">use std::{thread,time};<br/></span><span class="s1">use std::process;<br/></span><span class="s1">use std::io::prelude::*;<br/></span><span class="s1">use std::net::TcpListener;<br/><br/></span><span class="s1">fn serve(listener: TcpListener) -&gt; ! {<br/></span><span class="s1">   for stream in listener.incoming() {<br/></span><span class="s1">      let mut buffer = [0; 2048];<br/></span><span class="s1">      let mut tcp = stream.unwrap();<br/></span><span class="s1">      tcp.read(&amp;mut buffer).expect("tcp read failed");<br/></span><span class="s1">      let response = format!("respond from #{}\n", process::id());<br/></span><span class="s1">      tcp.write(response.as_bytes()).expect("tcp write failed");<br/></span><span class="s1">   }<br/></span><span class="s1">   panic!("unreachable");<br/></span><span class="s1">}<br/><br/></span><span class="s1">fn main() {<br/></span><span class="s1">   let listener = TcpListener::bind("127.0.0.1:8888").unwrap();<br/></span><span class="s1">   let mut children = Vec::new();<br/></span><span class="s1">   for _ in 0..3 {<br/></span><span class="s1">      match fork().expect("fork failed") {<br/></span><span class="s1">         ForkResult::Parent{ child: pid } =&gt; { children.push(pid); }<br/></span><span class="s1">         ForkResult::Child =&gt; { </span><span class="s1">serve(listener) </span><span class="s1">}<br/></span><span class="s1">      }<br/></span><span class="s1">   }<br/><br/></span><span class="s1">   let t = time::Duration::from_millis(1000);<br/></span><span class="s1">   loop {<br/></span><span class="s1">      thread::sleep(t);<br/></span><span class="s1">   }<br/></span><span class="s1">}</span></pre>
<p>In this example, we start listening for connections on port <kbd>8888</kbd>. Then, after forking three times, we start serving responses with our worker process. Sending requests to the server, we can confirm that separate processes are indeed competing to serve requests. Consider the following code:</p>
<pre class="p1" style="padding-left: 30px"><span class="s1">$ curl 'http://localhost:8888/'<br/></span><span class="s1">respond from #59485<br/></span><span class="s1">$ curl 'http://localhost:8888/'<br/></span><span class="s1">respond from #59486<br/></span><span class="s1">$ curl 'http://localhost:8888/'<br/></span><span class="s1">respond from #59487<br/></span><span class="s1">$ curl 'http://localhost:8888/'<br/></span><span class="s1">respond from #59485<br/></span><span class="s1">$ curl 'http://localhost:8888/'<br/></span><span class="s1">respond from #59486</span></pre>
<p class="p1">All three workers served at least one response. Combining the first strategy of memory sharing with this new concept of built-in load balancing, forked processes effectively solve several common problems where concurrency is desired.</p>
<p>However, the fork concurrency model is very rigid. Both of these tricks require planning the application to strategically fork after resources are allocated. Fork does not help at all after the processes have been split. In POSIX, there have been additional standards created to address this problem. Sending information over channels or sharing memory are a common pattern, much like in Rust. However, none of these solutions have proved as practical as threads.</p>
<p>Threads implicitly permit inter-process messaging and memory sharing. The risk of threads is that sharing messages or memory may not be thread-safe and may lead to memory corruption. Rust is built from the ground up to make threaded programming safer.</p>


            </article>

            
        </section>
    </body>

</html>